<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>ISLR 6: Linear Model Selection and Regularization â€¢ StatisticalLearning</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script><script src="../pkgdown.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">StatisticalLearning</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/03-LinearRegression.html">ISLR 3: Linear Regression</a>
    </li>
    <li>
      <a href="../articles/04-Classification.html">ISLR 4: Classification</a>
    </li>
    <li>
      <a href="../articles/05-CV-Resampling-Methods.html">ISLR 5: Resampling Methods</a>
    </li>
    <li>
      <a href="../articles/06-Model-Selection.html">ISLR 6: Linear Model Selection and Regularization</a>
    </li>
    <li>
      <a href="../articles/07-Nonlinear.html">Moving Beyond Linearity</a>
    </li>
    <li>
      <a href="../articles/08-Trees.html">Tree-Based Methods</a>
    </li>
    <li>
      <a href="../articles/09-SVM.html">Support Vector Machines</a>
    </li>
    <li>
      <a href="../articles/10-Unsupervised.html">Unsupervised Learning</a>
    </li>
    <li>
      <a href="../articles/quiz-05-CV-Resampling-Methods.html">ISLR: Bootstrap quiz</a>
    </li>
    <li>
      <a href="../articles/quiz-07-Nonlinear-Functions-in-R.html">ISLR: Nonlinear functions quiz</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>ISLR 6: Linear Model Selection and Regularization</h1>
            
          </div>

    
    
<div class="contents">

<div id="introduction" class="section level2">
<h2 class="hasAnchor">
<a href="#introduction" class="anchor"></a>Introduction</h2>
<p>Load the <code>ISLR</code> package and check the the <code>Hitters</code> data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ISLR)
<span class="kw">data</span>(Hitters)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">?Hitters</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">str</span>(Hitters)</code></pre></div>
<pre><code>## 'data.frame':    322 obs. of  20 variables:
##  $ AtBat    : int  293 315 479 496 321 594 185 298 323 401 ...
##  $ Hits     : int  66 81 130 141 87 169 37 73 81 92 ...
##  $ HmRun    : int  1 7 18 20 10 4 1 0 6 17 ...
##  $ Runs     : int  30 24 66 65 39 74 23 24 26 49 ...
##  $ RBI      : int  29 38 72 78 42 51 8 24 32 66 ...
##  $ Walks    : int  14 39 76 37 30 35 21 7 8 65 ...
##  $ Years    : int  1 14 3 11 2 11 2 3 2 13 ...
##  $ CAtBat   : int  293 3449 1624 5628 396 4408 214 509 341 5206 ...
##  $ CHits    : int  66 835 457 1575 101 1133 42 108 86 1332 ...
##  $ CHmRun   : int  1 69 63 225 12 19 1 0 6 253 ...
##  $ CRuns    : int  30 321 224 828 48 501 30 41 32 784 ...
##  $ CRBI     : int  29 414 266 838 46 336 9 37 34 890 ...
##  $ CWalks   : int  14 375 263 354 33 194 24 12 8 866 ...
##  $ League   : Factor w/ 2 levels "A","N": 1 2 1 2 2 1 2 1 2 1 ...
##  $ Division : Factor w/ 2 levels "E","W": 1 2 2 1 1 2 1 2 2 1 ...
##  $ PutOuts  : int  446 632 880 200 805 282 76 121 143 0 ...
##  $ Assists  : int  33 43 82 11 40 421 127 283 290 0 ...
##  $ Errors   : int  20 10 14 3 4 25 7 9 19 0 ...
##  $ Salary   : num  NA 475 480 500 91.5 750 70 100 75 1100 ...
##  $ NewLeague: Factor w/ 2 levels "A","N": 1 2 1 2 2 1 1 1 2 1 ...</code></pre>
<p>Are there any missing values?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">NA_index &lt;-<span class="st"> </span><span class="kw">is.na</span>(Hitters)
<span class="kw">length</span>(Hitters[NA_index])</code></pre></div>
<pre><code>## [1] 59</code></pre>
<p>There are 59 missing values here, so before we proceed we will remove them:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Hitters &lt;-<span class="st"> </span><span class="kw">na.omit</span>(Hitters)

NA_index &lt;-<span class="st"> </span><span class="kw">is.na</span>(Hitters)

<span class="kw">length</span>(Hitters[NA_index])</code></pre></div>
<pre><code>## [1] 0</code></pre>
</div>
<div id="best-subset-regression" class="section level2">
<h2 class="hasAnchor">
<a href="#best-subset-regression" class="anchor"></a>Best Subset regression</h2>
<p>We will now use the package <code>leaps</code> to evaluate all the best-subset models. It considers all possible variable combinations for each possible model size. The <code>*</code> in each row of the model output below signifies the chosen variable.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(leaps)

subset_full &lt;-<span class="st"> </span><span class="kw">regsubsets</span>(Salary <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> Hitters)
<span class="kw">summary</span>(subset_full)</code></pre></div>
<pre><code>## Subset selection object
## Call: regsubsets.formula(Salary ~ ., data = Hitters)
## 19 Variables  (and intercept)
##            Forced in Forced out
## AtBat          FALSE      FALSE
## Hits           FALSE      FALSE
## HmRun          FALSE      FALSE
## Runs           FALSE      FALSE
## RBI            FALSE      FALSE
## Walks          FALSE      FALSE
## Years          FALSE      FALSE
## CAtBat         FALSE      FALSE
## CHits          FALSE      FALSE
## CHmRun         FALSE      FALSE
## CRuns          FALSE      FALSE
## CRBI           FALSE      FALSE
## CWalks         FALSE      FALSE
## LeagueN        FALSE      FALSE
## DivisionW      FALSE      FALSE
## PutOuts        FALSE      FALSE
## Assists        FALSE      FALSE
## Errors         FALSE      FALSE
## NewLeagueN     FALSE      FALSE
## 1 subsets of each size up to 8
## Selection Algorithm: exhaustive
##          AtBat Hits HmRun Runs RBI Walks Years CAtBat CHits CHmRun CRuns
## 1  ( 1 ) " "   " "  " "   " "  " " " "   " "   " "    " "   " "    " "  
## 2  ( 1 ) " "   "*"  " "   " "  " " " "   " "   " "    " "   " "    " "  
## 3  ( 1 ) " "   "*"  " "   " "  " " " "   " "   " "    " "   " "    " "  
## 4  ( 1 ) " "   "*"  " "   " "  " " " "   " "   " "    " "   " "    " "  
## 5  ( 1 ) "*"   "*"  " "   " "  " " " "   " "   " "    " "   " "    " "  
## 6  ( 1 ) "*"   "*"  " "   " "  " " "*"   " "   " "    " "   " "    " "  
## 7  ( 1 ) " "   "*"  " "   " "  " " "*"   " "   "*"    "*"   "*"    " "  
## 8  ( 1 ) "*"   "*"  " "   " "  " " "*"   " "   " "    " "   "*"    "*"  
##          CRBI CWalks LeagueN DivisionW PutOuts Assists Errors NewLeagueN
## 1  ( 1 ) "*"  " "    " "     " "       " "     " "     " "    " "       
## 2  ( 1 ) "*"  " "    " "     " "       " "     " "     " "    " "       
## 3  ( 1 ) "*"  " "    " "     " "       "*"     " "     " "    " "       
## 4  ( 1 ) "*"  " "    " "     "*"       "*"     " "     " "    " "       
## 5  ( 1 ) "*"  " "    " "     "*"       "*"     " "     " "    " "       
## 6  ( 1 ) "*"  " "    " "     "*"       "*"     " "     " "    " "       
## 7  ( 1 ) " "  " "    " "     "*"       "*"     " "     " "    " "       
## 8  ( 1 ) " "  "*"    " "     "*"       "*"     " "     " "    " "</code></pre>
<p>Notice above, the default best-subsets up to size 8. Lets increase that to 19, which is all the variables, create <code>summary</code> statistics on the model and view their names. Calling names on the <code>full_summary</code> gives us the output categories it contains.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">subset_full &lt;-<span class="st"> </span><span class="kw">regsubsets</span>(Salary <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> Hitters, <span class="dt">nvmax =</span> <span class="dv">19</span>)

full_summary &lt;-<span class="st"> </span><span class="kw">summary</span>(subset_full)

<span class="kw">names</span>(full_summary)</code></pre></div>
<pre><code>## [1] "which"  "rsq"    "rss"    "adjr2"  "cp"     "bic"    "outmat" "obj"</code></pre>
<p>So lets plot the <code>Cp</code>, or the estimated prediction error, for each variable. As we are looking for the <code>Min</code>, we can use the <code>which.min</code> function and color it red.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(full_summary<span class="op">$</span>cp, <span class="dt">xlab =</span> <span class="st">"Number of Variables"</span>, <span class="dt">ylab =</span> <span class="st">"Cp"</span>)

<span class="kw">points</span>(<span class="kw">which.min</span>(full_summary<span class="op">$</span>cp), full_summary<span class="op">$</span>cp[<span class="kw">which.min</span>(full_summary<span class="op">$</span>cp)], 
    <span class="dt">pch =</span> <span class="dv">20</span>, <span class="dt">col =</span> <span class="st">"red"</span>)</code></pre></div>
<p><img src="06-Model-Selection_files/figure-html/unnamed-chunk-8-1.png" width="672"></p>
<p>There is a plot method designed specifically for the <code>regsubsets</code> object which is displayed below. It also plots the <code>Cp</code> statistic but each variable. Areas that are colored black indicate the variable is present in the model at the corresponding <code>Cp</code> level, while white areas communicate an absence of the variable.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(subset_full, <span class="dt">scale =</span> <span class="st">"Cp"</span>)</code></pre></div>
<p><img src="06-Model-Selection_files/figure-html/unnamed-chunk-9-1.png" width="672"></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">coef</span>(subset_full, <span class="dv">10</span>)</code></pre></div>
<pre><code>##  (Intercept)        AtBat         Hits        Walks       CAtBat 
##  162.5354420   -2.1686501    6.9180175    5.7732246   -0.1300798 
##        CRuns         CRBI       CWalks    DivisionW      PutOuts 
##    1.4082490    0.7743122   -0.8308264 -112.3800575    0.2973726 
##      Assists 
##    0.2831680</code></pre>
</div>
<div id="forward-stepwise-selection" class="section level2">
<h2 class="hasAnchor">
<a href="#forward-stepwise-selection" class="anchor"></a>Forward Stepwise Selection</h2>
<p>Here we use the <code>regsubsets</code> function but specify the <code>method="forward"</code> option:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">forward_step &lt;-<span class="st"> </span><span class="kw">regsubsets</span>(Salary <span class="op">~</span><span class="st"> </span>., <span class="dt">data=</span>Hitters, <span class="dt">nvmax=</span><span class="dv">19</span>, <span class="dt">method=</span><span class="st">"forward"</span>)
<span class="kw">summary</span>(forward_step)</code></pre></div>
<pre><code>## Subset selection object
## Call: regsubsets.formula(Salary ~ ., data = Hitters, nvmax = 19, method = "forward")
## 19 Variables  (and intercept)
##            Forced in Forced out
## AtBat          FALSE      FALSE
## Hits           FALSE      FALSE
## HmRun          FALSE      FALSE
## Runs           FALSE      FALSE
## RBI            FALSE      FALSE
## Walks          FALSE      FALSE
## Years          FALSE      FALSE
## CAtBat         FALSE      FALSE
## CHits          FALSE      FALSE
## CHmRun         FALSE      FALSE
## CRuns          FALSE      FALSE
## CRBI           FALSE      FALSE
## CWalks         FALSE      FALSE
## LeagueN        FALSE      FALSE
## DivisionW      FALSE      FALSE
## PutOuts        FALSE      FALSE
## Assists        FALSE      FALSE
## Errors         FALSE      FALSE
## NewLeagueN     FALSE      FALSE
## 1 subsets of each size up to 19
## Selection Algorithm: forward
##           AtBat Hits HmRun Runs RBI Walks Years CAtBat CHits CHmRun CRuns
## 1  ( 1 )  " "   " "  " "   " "  " " " "   " "   " "    " "   " "    " "  
## 2  ( 1 )  " "   "*"  " "   " "  " " " "   " "   " "    " "   " "    " "  
## 3  ( 1 )  " "   "*"  " "   " "  " " " "   " "   " "    " "   " "    " "  
## 4  ( 1 )  " "   "*"  " "   " "  " " " "   " "   " "    " "   " "    " "  
## 5  ( 1 )  "*"   "*"  " "   " "  " " " "   " "   " "    " "   " "    " "  
## 6  ( 1 )  "*"   "*"  " "   " "  " " "*"   " "   " "    " "   " "    " "  
## 7  ( 1 )  "*"   "*"  " "   " "  " " "*"   " "   " "    " "   " "    " "  
## 8  ( 1 )  "*"   "*"  " "   " "  " " "*"   " "   " "    " "   " "    "*"  
## 9  ( 1 )  "*"   "*"  " "   " "  " " "*"   " "   "*"    " "   " "    "*"  
## 10  ( 1 ) "*"   "*"  " "   " "  " " "*"   " "   "*"    " "   " "    "*"  
## 11  ( 1 ) "*"   "*"  " "   " "  " " "*"   " "   "*"    " "   " "    "*"  
## 12  ( 1 ) "*"   "*"  " "   "*"  " " "*"   " "   "*"    " "   " "    "*"  
## 13  ( 1 ) "*"   "*"  " "   "*"  " " "*"   " "   "*"    " "   " "    "*"  
## 14  ( 1 ) "*"   "*"  "*"   "*"  " " "*"   " "   "*"    " "   " "    "*"  
## 15  ( 1 ) "*"   "*"  "*"   "*"  " " "*"   " "   "*"    "*"   " "    "*"  
## 16  ( 1 ) "*"   "*"  "*"   "*"  "*" "*"   " "   "*"    "*"   " "    "*"  
## 17  ( 1 ) "*"   "*"  "*"   "*"  "*" "*"   " "   "*"    "*"   " "    "*"  
## 18  ( 1 ) "*"   "*"  "*"   "*"  "*" "*"   "*"   "*"    "*"   " "    "*"  
## 19  ( 1 ) "*"   "*"  "*"   "*"  "*" "*"   "*"   "*"    "*"   "*"    "*"  
##           CRBI CWalks LeagueN DivisionW PutOuts Assists Errors NewLeagueN
## 1  ( 1 )  "*"  " "    " "     " "       " "     " "     " "    " "       
## 2  ( 1 )  "*"  " "    " "     " "       " "     " "     " "    " "       
## 3  ( 1 )  "*"  " "    " "     " "       "*"     " "     " "    " "       
## 4  ( 1 )  "*"  " "    " "     "*"       "*"     " "     " "    " "       
## 5  ( 1 )  "*"  " "    " "     "*"       "*"     " "     " "    " "       
## 6  ( 1 )  "*"  " "    " "     "*"       "*"     " "     " "    " "       
## 7  ( 1 )  "*"  "*"    " "     "*"       "*"     " "     " "    " "       
## 8  ( 1 )  "*"  "*"    " "     "*"       "*"     " "     " "    " "       
## 9  ( 1 )  "*"  "*"    " "     "*"       "*"     " "     " "    " "       
## 10  ( 1 ) "*"  "*"    " "     "*"       "*"     "*"     " "    " "       
## 11  ( 1 ) "*"  "*"    "*"     "*"       "*"     "*"     " "    " "       
## 12  ( 1 ) "*"  "*"    "*"     "*"       "*"     "*"     " "    " "       
## 13  ( 1 ) "*"  "*"    "*"     "*"       "*"     "*"     "*"    " "       
## 14  ( 1 ) "*"  "*"    "*"     "*"       "*"     "*"     "*"    " "       
## 15  ( 1 ) "*"  "*"    "*"     "*"       "*"     "*"     "*"    " "       
## 16  ( 1 ) "*"  "*"    "*"     "*"       "*"     "*"     "*"    " "       
## 17  ( 1 ) "*"  "*"    "*"     "*"       "*"     "*"     "*"    "*"       
## 18  ( 1 ) "*"  "*"    "*"     "*"       "*"     "*"     "*"    "*"       
## 19  ( 1 ) "*"  "*"    "*"     "*"       "*"     "*"     "*"    "*"</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(forward_step, <span class="dt">scale =</span> <span class="st">"Cp"</span>)</code></pre></div>
<p><img src="06-Model-Selection_files/figure-html/unnamed-chunk-10-1.png" width="672"></p>
</div>
<div id="model-selection-using-a-validation-set" class="section level2">
<h2 class="hasAnchor">
<a href="#model-selection-using-a-validation-set" class="anchor"></a>Model Selection Using a Validation Set</h2>
<p>Lets make a training and validation set, so that we can choose a good subset model. We will do it using a slightly different approach from what was done in the the book.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dim</span>(Hitters)</code></pre></div>
<pre><code>## [1] 263  20</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1</span>)

train &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">seq</span>(<span class="dv">263</span>), <span class="dv">180</span>, <span class="dt">replace =</span> <span class="ot">FALSE</span>)

forward_step &lt;-<span class="st"> </span><span class="kw">regsubsets</span>(Salary <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> Hitters[train, ], <span class="dt">nvmax =</span> <span class="dv">19</span>, 
    <span class="dt">method =</span> <span class="st">"forward"</span>)</code></pre></div>
<p>Now we will make predictions on the observations not used for training. We know there are 19 models, so we set up some vectors to record the errors. We have to do a bit of work here, because there is no predict method for <code>regsubsets</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">val.errors &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, <span class="dv">19</span>)
x.test &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(Salary <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> Hitters[<span class="op">-</span>train, ])

<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">19</span>) {
    coefi &lt;-<span class="st"> </span><span class="kw">coef</span>(forward_step, <span class="dt">id =</span> i)
    pred &lt;-<span class="st"> </span>x.test[, <span class="kw">names</span>(coefi)] <span class="op">%*%</span><span class="st"> </span>coefi
    val.errors[i] &lt;-<span class="st"> </span><span class="kw">mean</span>((Hitters<span class="op">$</span>Salary[<span class="op">-</span>train] <span class="op">-</span><span class="st"> </span>pred)<span class="op">^</span><span class="dv">2</span>)
}

<span class="kw">plot</span>(<span class="kw">sqrt</span>(val.errors), <span class="dt">ylab =</span> <span class="st">"Root MSE"</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">300</span>, <span class="dv">400</span>), <span class="dt">pch =</span> <span class="dv">19</span>, <span class="dt">type =</span> <span class="st">"b"</span>)
<span class="kw">points</span>(<span class="kw">sqrt</span>(forward_step<span class="op">$</span>rss[<span class="op">-</span><span class="dv">1</span>]<span class="op">/</span><span class="dv">180</span>), <span class="dt">col =</span> <span class="st">"green"</span>, <span class="dt">pch =</span> <span class="dv">19</span>, <span class="dt">type =</span> <span class="st">"b"</span>)
<span class="kw">legend</span>(<span class="st">"topright"</span>, <span class="dt">legend =</span> <span class="kw">c</span>(<span class="st">"Training"</span>, <span class="st">"Validation"</span>), <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">"green"</span>, <span class="st">"black"</span>), 
    <span class="dt">pch =</span> <span class="dv">19</span>)</code></pre></div>
<p><img src="06-Model-Selection_files/figure-html/unnamed-chunk-12-1.png" width="672"></p>
<p>As we expect, the training error goes down monotonically as the model gets bigger, but not so for the validation error.</p>
<p>This was a little tedious - not having a predict method for <code>regsubsets</code>. So we will write a generic function for it.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">predict.regsubsets &lt;-<span class="st"> </span><span class="cf">function</span>(object, newdata, id, ...){
                        form &lt;-<span class="st"> </span><span class="kw">as.formula</span>(object<span class="op">$</span>call[[<span class="dv">2</span>]])
                        mat &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(form, newdata)
                        coefi &lt;-<span class="st"> </span><span class="kw">coef</span>(object, <span class="dt">id =</span> id)
                        mat[ ,<span class="kw">names</span>(coefi)] <span class="op">%*%</span><span class="st"> </span>coefi
}</code></pre></div>
</div>
<div id="model-selection-by-cross-validation" class="section level2">
<h2 class="hasAnchor">
<a href="#model-selection-by-cross-validation" class="anchor"></a>Model Selection by Cross-Validation</h2>
<p>We will do 10-fold cross-validation. Its really easy!</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">11</span>)
folds &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>, <span class="dt">length =</span> <span class="kw">nrow</span>(Hitters)))
folds</code></pre></div>
<pre><code>##   [1]  3  1  4  4  7  7  3  5  5  2  5  2  8  3  3  3  9  2  9  8 10  5  8
##  [24]  5  5  5  5 10 10  4  4  7  6  7  7  7  3  4  8  3  6  8 10  4  3  9
##  [47]  9  3  4  9  8  7 10  6 10  3  6  9  4  2  8  2  5  6 10  7  2  8  8
##  [70]  1  3  6  2  5  8  1  1  2  8  1 10  1  2  3  6  6  5  8  8 10  4  2
##  [93]  6  1  7  4  8  3  7  8  7  1 10  1  6  2  9 10  1  7  7  4  7  4 10
## [116]  3  6 10  6  6  9  8 10  6  7  9  6  7  1 10  2  2  5  9  9  6  1  1
## [139]  2  9  4 10  5  3  7  7 10 10  9  3  3  7  3  1  4  6  6 10  4  9  9
## [162]  1  3  6  8 10  8  5  4  5  6  2  9 10  3  7  7  6  6  2  3  2  4  4
## [185]  4  4  8  2  3  5  9  9 10  2  1  3  9  6  7  3  1  9  4 10 10  8  8
## [208]  8  2  5  9  8 10  5  8  2  4  1  4  4  5  5  2  1  9  5  2  9  9  5
## [231]  3  2  1  9  1  7  2  5  8  1  1  7  6  6  4  5 10  5  7  4  8  6  9
## [254]  1  2  5  7  1  3  1  3  1  2</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">table</span>(folds)</code></pre></div>
<pre><code>## folds
##  1  2  3  4  5  6  7  8  9 10 
## 27 27 27 26 26 26 26 26 26 26</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cv.errors &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="ot">NA</span>, <span class="dv">10</span>, <span class="dv">19</span>)

<span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">10</span>) {
    best.fit &lt;-<span class="st"> </span><span class="kw">regsubsets</span>(Salary <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> Hitters[folds <span class="op">!=</span><span class="st"> </span>k, ], <span class="dt">nvmax =</span> <span class="dv">19</span>, 
        <span class="dt">method =</span> <span class="st">"forward"</span>)
    <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">19</span>) {
        pred &lt;-<span class="st"> </span><span class="kw">predict</span>(best.fit, Hitters[folds <span class="op">==</span><span class="st"> </span>k, ], <span class="dt">id =</span> i)
        cv.errors[k, i] &lt;-<span class="st"> </span><span class="kw">mean</span>((Hitters<span class="op">$</span>Salary[folds <span class="op">==</span><span class="st"> </span>k] <span class="op">-</span><span class="st"> </span>pred)<span class="op">^</span><span class="dv">2</span>)
    }
}

rmse.cv &lt;-<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">apply</span>(cv.errors, <span class="dv">2</span>, mean))

<span class="kw">plot</span>(rmse.cv, <span class="dt">col =</span> <span class="st">"blue"</span>, <span class="dt">pch =</span> <span class="dv">19</span>, <span class="dt">type =</span> <span class="st">"b"</span>)</code></pre></div>
<p><img src="06-Model-Selection_files/figure-html/unnamed-chunk-14-1.png" width="672"></p>
</div>
<div id="ridge-regression-and-the-lasso" class="section level2">
<h2 class="hasAnchor">
<a href="#ridge-regression-and-the-lasso" class="anchor"></a>Ridge Regression and the Lasso</h2>
<p>We will use the package <code>glmnet</code>, which does not use the model formula language, so we will set up an <code>x</code> and <code>y</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(glmnet)</code></pre></div>
<pre><code>## Loading required package: Matrix</code></pre>
<pre><code>## Loading required package: foreach</code></pre>
<pre><code>## Loaded glmnet 2.0-13</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">?glmnet

x &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(Salary <span class="op">~</span><span class="st"> </span>.<span class="op">-</span><span class="dv">1</span>, <span class="dt">data =</span> Hitters) 

y &lt;-<span class="st"> </span>Hitters<span class="op">$</span>Salary</code></pre></div>
<p>First we will fit a ridge-regression model. Use <code>glmnet</code> with <code>alpha = 0</code>. Remember from the lectures, ridge regression penalizes by the sum squares of the coefficients. It takes the usual linear regression Residual Sum of Squares (<span class="math inline">\(RSS\)</span>), and has been modified by adding a penalty placed on the coefficients.</p>
<p><span class="math display">\[RSS + \lambda\sum_{j=1}^p\beta_j^2\]</span></p>
<p>As <span class="math inline">\(\lambda\)</span> increases, the coefficients shrink to zero. The following plot illustrates this relationship well. When <span class="math inline">\(\lambda = 0\)</span>, you have the coefficients of linear regression, with their parameters resting on the y-axis where x = 0.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ridge_model &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/glmnet/topics/glmnet">glmnet</a></span>(x, y, <span class="dt">alpha =</span> <span class="dv">0</span>)

<span class="kw">plot</span>(ridge_model, <span class="dt">xvar =</span> <span class="st">"lambda"</span>, <span class="dt">label =</span> <span class="ot">TRUE</span>)</code></pre></div>
<p><img src="06-Model-Selection_files/figure-html/unnamed-chunk-16-1.png" width="672"> here is also a <code>cv.glmnet</code> function which will do the cross-validation for us and has a plot method.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cv_ridge_model &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/glmnet/topics/cv.glmnet">cv.glmnet</a></span>(x, y, <span class="dt">alpha =</span> <span class="dv">0</span>)

<span class="kw">plot</span>(cv_ridge_model)</code></pre></div>
<p><img src="06-Model-Selection_files/figure-html/unnamed-chunk-17-1.png" width="672"></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">str</span>(cv_ridge_model)</code></pre></div>
<pre><code>## List of 10
##  $ lambda    : num [1:99] 255282 232604 211940 193112 175956 ...
##  $ cvm       : num [1:99] 203819 202160 201518 201275 201010 ...
##  $ cvsd      : num [1:99] 15885 15831 15732 15720 15706 ...
##  $ cvup      : num [1:99] 219704 217991 217250 216995 216716 ...
##  $ cvlo      : num [1:99] 187935 186329 185786 185555 185303 ...
##  $ nzero     : Named int [1:99] 20 20 20 20 20 20 20 20 20 20 ...
##   ..- attr(*, "names")= chr [1:99] "s0" "s1" "s2" "s3" ...
##  $ name      : Named chr "Mean-Squared Error"
##   ..- attr(*, "names")= chr "mse"
##  $ glmnet.fit:List of 12
##   ..$ a0       : Named num [1:100] 536 528 527 526 525 ...
##   .. ..- attr(*, "names")= chr [1:100] "s0" "s1" "s2" "s3" ...
##   ..$ beta     :Formal class 'dgCMatrix' [package "Matrix"] with 6 slots
##   .. .. ..@ i       : int [1:2000] 0 1 2 3 4 5 6 7 8 9 ...
##   .. .. ..@ p       : int [1:101] 0 20 40 60 80 100 120 140 160 180 ...
##   .. .. ..@ Dim     : int [1:2] 20 100
##   .. .. ..@ Dimnames:List of 2
##   .. .. .. ..$ : chr [1:20] "AtBat" "Hits" "HmRun" "Runs" ...
##   .. .. .. ..$ : chr [1:100] "s0" "s1" "s2" "s3" ...
##   .. .. ..@ x       : num [1:2000] 1.22e-36 4.43e-36 1.78e-35 7.49e-36 7.91e-36 ...
##   .. .. ..@ factors : list()
##   ..$ df       : int [1:100] 20 20 20 20 20 20 20 20 20 20 ...
##   ..$ dim      : int [1:2] 20 100
##   ..$ lambda   : num [1:100] 255282 232604 211940 193112 175956 ...
##   ..$ dev.ratio: num [1:100] 6.19e-36 1.16e-02 1.27e-02 1.39e-02 1.53e-02 ...
##   ..$ nulldev  : num 53319113
##   ..$ npasses  : int 701
##   ..$ jerr     : int 0
##   ..$ offset   : logi FALSE
##   ..$ call     : language glmnet(x = x, y = y, alpha = 0)
##   ..$ nobs     : int 263
##   ..- attr(*, "class")= chr [1:2] "elnet" "glmnet"
##  $ lambda.min: num 28
##  $ lambda.1se: num 2220
##  - attr(*, "class")= chr "cv.glmnet"</code></pre>
<p>Now we fit a lasso model, calling <code>glmnet</code> but using the default <code>alpha=1</code>. This time, instead of penalizing the sum of squares of the coefficients, we penalize their absolute values instead. This actually restricts some coefficients to be exactly zero, which makes them effectively NULL. Your variable selection has now been performed for you in a much more efficient manner than the subset and step-wise methods.</p>
<p><span class="math display">\[RSS + \lambda\sum_{j=1}^p\lvert\beta_j\rvert\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lasso_model &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/glmnet/topics/glmnet">glmnet</a></span>(x, y, <span class="dt">alpha =</span> <span class="dv">1</span>)
<span class="kw">plot</span>(lasso_model, <span class="dt">xvar =</span> <span class="st">"lambda"</span>, <span class="dt">label=</span><span class="ot">TRUE</span>)</code></pre></div>
<p><img src="06-Model-Selection_files/figure-html/unnamed-chunk-18-1.png" width="672"></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(lasso_model, <span class="dt">xvar =</span> <span class="st">"dev"</span>, <span class="dt">label=</span><span class="ot">TRUE</span>)</code></pre></div>
<p><img src="06-Model-Selection_files/figure-html/unnamed-chunk-18-2.png" width="672"></p>
<p>Lets use Cross-Validation for the Lasso.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cv.lasso &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/glmnet/topics/cv.glmnet">cv.glmnet</a></span>(x, y, <span class="dt">alpha =</span> <span class="dv">1</span>)
<span class="kw">plot</span>(cv.lasso)</code></pre></div>
<p><img src="06-Model-Selection_files/figure-html/unnamed-chunk-19-1.png" width="672"></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">coef</span>(cv.lasso)</code></pre></div>
<pre><code>## 21 x 1 sparse Matrix of class "dgCMatrix"
##                        1
## (Intercept) 127.95694754
## AtBat         .         
## Hits          1.42342566
## HmRun         .         
## Runs          .         
## RBI           .         
## Walks         1.58214111
## Years         .         
## CAtBat        .         
## CHits         .         
## CHmRun        .         
## CRuns         0.16027975
## CRBI          0.33667715
## CWalks        .         
## LeagueA       .         
## LeagueN       .         
## DivisionW    -8.06171262
## PutOuts       0.08393604
## Assists       .         
## Errors        .         
## NewLeagueN    .</code></pre>
<p>Suppose we want to use our earlier train/validation set to select the <code>lambda</code> for the lasso.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lasso_train &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/glmnet/topics/glmnet">glmnet</a></span>(x[train,],y[train])

lasso_train</code></pre></div>
<pre><code>## 
## Call:  glmnet(x = x[train, ], y = y[train]) 
## 
##       Df    %Dev    Lambda
##  [1,]  0 0.00000 246.40000
##  [2,]  1 0.05013 224.50000
##  [3,]  1 0.09175 204.60000
##  [4,]  2 0.13840 186.40000
##  [5,]  2 0.18000 169.80000
##  [6,]  3 0.21570 154.80000
##  [7,]  3 0.24710 141.00000
##  [8,]  3 0.27320 128.50000
##  [9,]  4 0.30010 117.10000
## [10,]  4 0.32360 106.70000
## [11,]  4 0.34310  97.19000
## [12,]  4 0.35920  88.56000
## [13,]  5 0.37360  80.69000
## [14,]  5 0.38900  73.52000
## [15,]  5 0.40190  66.99000
## [16,]  5 0.41260  61.04000
## [17,]  5 0.42140  55.62000
## [18,]  5 0.42880  50.67000
## [19,]  5 0.43490  46.17000
## [20,]  5 0.43990  42.07000
## [21,]  5 0.44410  38.33000
## [22,]  5 0.44760  34.93000
## [23,]  6 0.45140  31.83000
## [24,]  7 0.45480  29.00000
## [25,]  7 0.45770  26.42000
## [26,]  7 0.46010  24.07000
## [27,]  8 0.46220  21.94000
## [28,]  8 0.46380  19.99000
## [29,]  8 0.46520  18.21000
## [30,]  8 0.46630  16.59000
## [31,]  8 0.46730  15.12000
## [32,]  8 0.46810  13.78000
## [33,]  9 0.47110  12.55000
## [34,]  9 0.47380  11.44000
## [35,]  9 0.47620  10.42000
## [36,] 10 0.48050   9.49500
## [37,]  9 0.48450   8.65200
## [38,] 10 0.48770   7.88300
## [39,] 10 0.49360   7.18300
## [40,] 11 0.49890   6.54500
## [41,] 12 0.50450   5.96300
## [42,] 12 0.51010   5.43400
## [43,] 13 0.51470   4.95100
## [44,] 13 0.51850   4.51100
## [45,] 13 0.52170   4.11000
## [46,] 14 0.52440   3.74500
## [47,] 14 0.52670   3.41200
## [48,] 15 0.52870   3.10900
## [49,] 15 0.53030   2.83300
## [50,] 15 0.53160   2.58100
## [51,] 16 0.53280   2.35200
## [52,] 17 0.53420   2.14300
## [53,] 18 0.53580   1.95300
## [54,] 18 0.53760   1.77900
## [55,] 18 0.53890   1.62100
## [56,] 18 0.54000   1.47700
## [57,] 18 0.54090   1.34600
## [58,] 18 0.54160   1.22600
## [59,] 18 0.54220   1.11700
## [60,] 18 0.54280   1.01800
## [61,] 18 0.54320   0.92770
## [62,] 18 0.54360   0.84530
## [63,] 18 0.54380   0.77020
## [64,] 19 0.54410   0.70180
## [65,] 19 0.54430   0.63940
## [66,] 19 0.54450   0.58260
## [67,] 19 0.54470   0.53090
## [68,] 19 0.54490   0.48370
## [69,] 20 0.54510   0.44070
## [70,] 20 0.54520   0.40160
## [71,] 20 0.54530   0.36590
## [72,] 20 0.54540   0.33340
## [73,] 20 0.54550   0.30380
## [74,] 20 0.54560   0.27680
## [75,] 20 0.54570   0.25220
## [76,] 20 0.54570   0.22980
## [77,] 20 0.54580   0.20940
## [78,] 20 0.54580   0.19080
## [79,] 20 0.54590   0.17380
## [80,] 20 0.54590   0.15840
## [81,] 20 0.54590   0.14430
## [82,] 20 0.54590   0.13150
## [83,] 20 0.54600   0.11980
## [84,] 19 0.54600   0.10920
## [85,] 19 0.54600   0.09948
## [86,] 19 0.54600   0.09064
## [87,] 19 0.54600   0.08259
## [88,] 20 0.54600   0.07525
## [89,] 20 0.54600   0.06856</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pred &lt;-<span class="st"> </span><span class="kw">predict</span>(lasso_train, x[<span class="op">-</span>train, ])

<span class="kw">dim</span>(pred)</code></pre></div>
<pre><code>## [1] 83 89</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rmse &lt;-<span class="st">  </span><span class="kw">sqrt</span>(<span class="kw">apply</span>((y[<span class="op">-</span>train]<span class="op">-</span>pred)<span class="op">^</span><span class="dv">2</span>, <span class="dv">2</span>, mean))
<span class="kw">plot</span>(<span class="kw">log</span>(lasso_train<span class="op">$</span>lambda), rmse, <span class="dt">type =</span> <span class="st">"b"</span>, <span class="dt">xlab =</span> <span class="st">"Log(lambda)"</span>)</code></pre></div>
<p><img src="06-Model-Selection_files/figure-html/unnamed-chunk-21-1.png" width="672"></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lambda_best &lt;-<span class="st"> </span>lasso_train<span class="op">$</span>lambda[<span class="kw">order</span>(rmse)[<span class="dv">1</span>]]

lambda_best</code></pre></div>
<pre><code>## [1] 19.98706</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">coef</span>(lasso_train, <span class="dt">s =</span> lambda_best)</code></pre></div>
<pre><code>## 21 x 1 sparse Matrix of class "dgCMatrix"
##                        1
## (Intercept)  107.9416686
## AtBat          .        
## Hits           0.1591252
## HmRun          .        
## Runs           .        
## RBI            1.7340039
## Walks          3.4657091
## Years          .        
## CAtBat         .        
## CHits          .        
## CHmRun         .        
## CRuns          0.5386855
## CRBI           .        
## CWalks         .        
## LeagueA      -30.0493021
## LeagueN        .        
## DivisionW   -113.8317016
## PutOuts        0.2915409
## Assists        .        
## Errors         .        
## NewLeagueN     2.0367518</code></pre>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#introduction">Introduction</a></li>
      <li><a href="#best-subset-regression">Best Subset regression</a></li>
      <li><a href="#forward-stepwise-selection">Forward Stepwise Selection</a></li>
      <li><a href="#model-selection-using-a-validation-set">Model Selection Using a Validation Set</a></li>
      <li><a href="#model-selection-by-cross-validation">Model Selection by Cross-Validation</a></li>
      <li><a href="#ridge-regression-and-the-lasso">Ridge Regression and the Lasso</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Justin M. Shea.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
